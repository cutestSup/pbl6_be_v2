{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "667f07ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load from imagenet\n",
      "BRIGHT + high_contrast + clearBrightness=166, Contrast=157\n",
      "Preds: torch.Size([1, 2, 1088, 736]) 0.0004289679345674813 0.9976726174354553\n",
      "Số box detect được: 311\n",
      "Đã lưu kết quả detect vào result_detect.txt\n",
      "Đã lưu ảnh kết quả: result_detect.jpg\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import yaml\n",
    "import numpy as np\n",
    "from addict import Dict\n",
    "from pathlib import Path\n",
    "from segmentation.models import build_model\n",
    "from segmentation.post_processing import get_post_processing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ===================== ADAPTIVE PREPROCESSOR v5 =====================\n",
    "class AdaptivePreprocessor:\n",
    "\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.base_strategies = {\n",
    "            'very_dark': {'clahe_clip': 8.0, 'tile': (8, 8), 'bilateral': (7, 50, 50), 'denoise': (10, 10, 7, 21)},\n",
    "            'dark': {'clahe_clip': 6.0, 'tile': (8, 8), 'bilateral': (7, 40, 40), 'denoise': (10, 10, 7, 21)},\n",
    "            'normal': {'clahe_clip': 3.0, 'tile': (16, 16), 'bilateral': (5, 30, 30), 'denoise': (5, 5, 3, 10)},\n",
    "            'bright': {'clahe_clip': 1.5, 'tile': (16, 16), 'bilateral': (5, 20, 20), 'denoise': (5, 5, 3, 10)},\n",
    "            'very_bright': {'clahe_clip': 1.0, 'tile': (16, 16), 'bilateral': (3, 15, 15), 'denoise': (5, 5, 3, 10)},\n",
    "        }\n",
    "    \n",
    "    def analyze_image(self, img_bgr):\n",
    "        gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "        h, w = img_bgr.shape[:2]\n",
    "        \n",
    "        mean = np.mean(gray)\n",
    "        std = np.std(gray)\n",
    "        percentile_5 = np.percentile(gray, 5)\n",
    "        percentile_95 = np.percentile(gray, 95)\n",
    "        contrast = percentile_95 - percentile_5\n",
    "        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "        \n",
    "        return {\n",
    "            'mean': mean,\n",
    "            'std': std,\n",
    "            'percentile_5': percentile_5,\n",
    "            'percentile_95': percentile_95,\n",
    "            'contrast': contrast,\n",
    "            'laplacian_var': laplacian_var,\n",
    "            'shape': (h, w),\n",
    "            'gray': gray\n",
    "        }\n",
    "    \n",
    "    def classify_image(self, metrics):\n",
    "        mean = metrics['mean']\n",
    "        contrast = metrics['contrast']\n",
    "        laplacian_var = metrics['laplacian_var']\n",
    "        \n",
    "        if mean < 50:\n",
    "            primary = 'very_dark'\n",
    "        elif mean < 100:\n",
    "            primary = 'dark'\n",
    "        elif mean < 150:\n",
    "            primary = 'normal'\n",
    "        elif mean < 200:\n",
    "            primary = 'bright'\n",
    "        else:\n",
    "            primary = 'very_bright'\n",
    "        \n",
    "        return primary, {\n",
    "            'is_high_contrast': contrast > 100,\n",
    "            'is_low_contrast': contrast < 50,\n",
    "            'is_blur': laplacian_var < 80,\n",
    "            'is_clear': laplacian_var > 1000,\n",
    "        }\n",
    "    \n",
    "    def adapt_strategy(self, primary, characteristics):\n",
    "        strategy = self.base_strategies[primary].copy()\n",
    "        \n",
    "        if characteristics['is_high_contrast']:\n",
    "            strategy['clahe_clip'] = min(strategy['clahe_clip'] * 1.5, 8.0)\n",
    "            d, s1, s2 = strategy['bilateral']\n",
    "            strategy['bilateral'] = (d, min(s1 + 10, 70), min(s2 + 10, 70))\n",
    "        \n",
    "        if characteristics['is_low_contrast']:\n",
    "            strategy['clahe_clip'] = min(strategy['clahe_clip'] * 2.0, 8.0)\n",
    "            strategy['tile'] = (8, 8)\n",
    "        \n",
    "        if characteristics['is_blur']:\n",
    "            strategy['clahe_clip'] = max(strategy['clahe_clip'] * 0.7, 0.5)\n",
    "            d, s1, s2 = strategy['bilateral']\n",
    "            strategy['bilateral'] = (d, max(s1 - 10, 5), max(s2 - 10, 5))\n",
    "        \n",
    "        if characteristics['is_clear']:\n",
    "            d, s1, s2 = strategy['bilateral']\n",
    "            strategy['bilateral'] = (d, min(s1 + 20, 80), min(s2 + 20, 80))\n",
    "        \n",
    "        return strategy\n",
    "    \n",
    "    def preprocess(self, img_bgr, short_size=736, img_name=None):\n",
    "        metrics = self.analyze_image(img_bgr)\n",
    "        primary, characteristics = self.classify_image(metrics)\n",
    "        strategy = self.adapt_strategy(primary, characteristics)\n",
    "        \n",
    "        print(f\"{primary.upper()}\", end=\"\")\n",
    "        if characteristics['is_high_contrast']: print(\" + high_contrast\", end=\"\")\n",
    "        if characteristics['is_low_contrast']: print(\" + low_contrast\", end=\"\")\n",
    "        if characteristics['is_blur']: print(\" + blur\", end=\"\")\n",
    "        if characteristics['is_clear']: print(\" + clear\", end=\"\")\n",
    "        print(f\"Brightness={metrics['mean']:.0f}, Contrast={metrics['contrast']:.0f}\")\n",
    "        \n",
    "        gray = metrics['gray']\n",
    "        \n",
    "        h, w = img_bgr.shape[:2]\n",
    "        scale = short_size * 1.0 / min(h, w)\n",
    "        new_h = int(h * scale + 0.5)\n",
    "        new_w = int(w * scale + 0.5)\n",
    "        new_h = (new_h + 31) // 32 * 32\n",
    "        new_w = (new_w + 31) // 32 * 32\n",
    "        gray = cv2.resize(gray, (new_w, new_h))\n",
    "        \n",
    "        # === BƯỚC 1: Normalize ===\n",
    "        if primary in ['very_dark', 'dark']:\n",
    "            gray = cv2.normalize(gray, None, alpha=40, beta=220, norm_type=cv2.NORM_MINMAX)\n",
    "        elif primary in ['very_bright', 'bright']:\n",
    "            gray = cv2.normalize(gray, None, alpha=50, beta=230, norm_type=cv2.NORM_MINMAX)\n",
    "        else:\n",
    "            gray = cv2.normalize(gray, None, alpha=30, beta=220, norm_type=cv2.NORM_MINMAX)\n",
    "        \n",
    "        # === BƯỚC 2: CLAHE ===\n",
    "        clahe = cv2.createCLAHE(clipLimit=strategy['clahe_clip'], tileGridSize=strategy['tile'])\n",
    "        gray = clahe.apply(gray)\n",
    "        \n",
    "        # === BƯỚC 3: Bilateral Filter ===\n",
    "        d, sigma1, sigma2 = strategy['bilateral']\n",
    "        gray = cv2.bilateralFilter(gray, d, sigma1, sigma2)\n",
    "        \n",
    "        # === BƯỚC 4: Morphological Operations ===\n",
    "        if primary in ['very_dark', 'dark']:\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "            gray = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "        \n",
    "        # === BƯỚC 5: Non-local Means Denoising ===\n",
    "        denoise_h, denoise_template, denoise_search, denoise_strength = strategy['denoise']\n",
    "        gray_bgr = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
    "        gray_bgr = cv2.fastNlMeansDenoisingColored(gray_bgr, None, denoise_h, denoise_template, denoise_search, denoise_strength)\n",
    "        gray = cv2.cvtColor(gray_bgr, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # === BƯỚC 6: Edge Enhancement ===\n",
    "        if metrics['laplacian_var'] > 80:\n",
    "            blur_enh = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "            gray = cv2.addWeighted(gray, 1.2, blur_enh, -0.2, 0)\n",
    "            gray = np.clip(gray, 0, 255).astype(np.uint8)\n",
    "        \n",
    "        enhanced = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
    "        img_tensor = torch.from_numpy(enhanced).permute(2, 0, 1).unsqueeze(0).float() / 255.0\n",
    "        \n",
    "        return img_tensor, enhanced, (new_h, new_w)\n",
    "\n",
    "\n",
    "preprocessor = AdaptivePreprocessor()\n",
    "\n",
    "def preprocess_intelligent(img_bgr, short_size=736, img_name=None):\n",
    "    return preprocessor.preprocess(img_bgr, short_size, img_name)\n",
    "\n",
    "def visualize_detection(img, boxes, scores, conf_threshold=0.5):\n",
    "    result = img.copy()\n",
    "    \n",
    "    for box, score in zip(boxes, scores):\n",
    "        if score < conf_threshold:\n",
    "            continue\n",
    "        \n",
    "        pts = np.array(box, dtype=np.int32).reshape(-1, 1, 2)\n",
    "        cv2.polylines(result, [pts], True, (0, 255, 0), 2)\n",
    "        \n",
    "        x1, y1 = int(box[0][0]), int(box[0][1])\n",
    "        cv2.putText(result, f'{score:.2f}', (x1, y1-5), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 1)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# ===================== LOAD MODEL =====================\n",
    "with open(\"D:/pbl6_be_v2/app/config/icdar2015_resnet18_FPN_DBhead_polyLR.yaml\", \"r\") as f:\n",
    "    cfg = Dict(yaml.safe_load(f))\n",
    "\n",
    "if \"in_channels\" not in cfg[\"arch\"][\"backbone\"]:\n",
    "    cfg[\"arch\"][\"backbone\"][\"in_channels\"] = 3\n",
    "\n",
    "model = build_model(cfg[\"arch\"])\n",
    "checkpoint = torch.load(\n",
    "    \"D:/pbl6_be_v2/app/weights/model_best.pth\",\n",
    "    map_location=\"cpu\"\n",
    ")\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "model.eval()\n",
    "\n",
    "post_process = get_post_processing(cfg[\"post_processing\"])\n",
    "\n",
    "\n",
    "# ===================== INFERENCE =====================\n",
    "img_path = \"D:/pbl6_be_v2/test_jpg.jpg\"\n",
    "img_bgr = cv2.imread(img_path)\n",
    "if img_bgr is None:\n",
    "    raise FileNotFoundError(f\"Không đọc được ảnh: {img_path}\")\n",
    "\n",
    "orig_h, orig_w = img_bgr.shape[:2]\n",
    "img_tensor, preprocessed_bgr, (target_h, target_w) = preprocess_intelligent(img_bgr, 736, Path(img_path).stem)\n",
    "\n",
    "with torch.no_grad():\n",
    "    preds = model(img_tensor)\n",
    "    print(\"Preds:\", preds.shape, preds.min().item(), preds.max().item())\n",
    "\n",
    "# ===================== POST PROCESS =====================\n",
    "batch = {\"shape\": [(orig_h, orig_w)]}\n",
    "boxes, scores = post_process(batch, preds, is_output_polygon=False)\n",
    "print(f\"Số box detect được: {len(boxes[0])}\")\n",
    "\n",
    "# ===================== SAVE RESULTS =====================\n",
    "output_txt = \"result_detect.txt\"\n",
    "with open(output_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "    for i, box in enumerate(boxes[0]):\n",
    "        score = scores[0][i] if scores is not None else 1.0\n",
    "        coords = [f\"{int(x)},{int(y)}\" for (x, y) in box]\n",
    "        f.write(f\"{','.join(coords)},{score:.2f}\\n\")\n",
    "print(f\"Đã lưu kết quả detect vào {output_txt}\")\n",
    "\n",
    "# ===================== VẼ KẾT QUẢ =====================\n",
    "img_show = img_bgr.copy()\n",
    "for i, box in enumerate(boxes[0]):\n",
    "    pts = np.array(box, np.int32).reshape((-1, 1, 2))\n",
    "    cv2.polylines(img_show, [pts], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "cv2.imwrite(\"result_detect.jpg\", img_show)\n",
    "print(\"Đã lưu ảnh kết quả: result_detect.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52315b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã đọc 267 box từ file detect\n",
      "Gom thành 32 dòng (theo reading order left->right).\n",
      "Đã lưu ảnh debug: D:/pbl6_be_v2/sorted_boxes_debug.jpg\n",
      "✔ Đã hoàn thành OCR và lưu kết quả vào: D:/pbl6_be_v2/ocr_results.txt\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "from vietocr.tool.predictor import Predictor\n",
    "from vietocr.tool.config import Cfg\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "\n",
    "# ---------------------------\n",
    "# HÀM TIỆN ÍCH\n",
    "# ---------------------------\n",
    "def clamp(val, lo, hi):\n",
    "    return max(lo, min(hi, val))\n",
    "\n",
    "# ---------------------------\n",
    "# NHÓM LINES THEO Y (median-height based)\n",
    "# ---------------------------\n",
    "def group_lines_by_median(boxes, med_h_factor=0.6):\n",
    "    \"\"\"\n",
    "    boxes: list of [x1,y1,x2,y2]\n",
    "    Trả về: list of lines, mỗi line là list of boxes (kept as [x1,y1,x2,y2])\n",
    "    \"\"\"\n",
    "    if not boxes:\n",
    "        return []\n",
    "\n",
    "    arr = np.array(boxes, dtype=float)\n",
    "    y_centers = (arr[:,1] + arr[:,3]) / 2.0\n",
    "    heights = (arr[:,3] - arr[:,1])\n",
    "    median_h = float(np.median(heights)) if len(heights)>0 else 0.0\n",
    "    if median_h <= 0:\n",
    "        median_h = float(np.mean(heights)) if len(heights)>0 else 10.0\n",
    "\n",
    "    # sort by y_center\n",
    "    order = np.argsort(y_centers)\n",
    "    arr_sorted = arr[order]\n",
    "\n",
    "    y_thresh = median_h * med_h_factor\n",
    "\n",
    "    lines = []\n",
    "    current = [arr_sorted[0].tolist()]\n",
    "    current_mean_y = y_centers[order[0]]\n",
    "\n",
    "    for r in arr_sorted[1:]:\n",
    "        cy = (r[1] + r[3]) / 2.0\n",
    "        if abs(cy - current_mean_y) <= y_thresh:\n",
    "            current.append(r.tolist())\n",
    "            # update mean\n",
    "            current_mean_y = np.mean([ (b[1]+b[3])/2.0 for b in current ])\n",
    "        else:\n",
    "            lines.append(current)\n",
    "            current = [r.tolist()]\n",
    "            current_mean_y = cy\n",
    "    lines.append(current)\n",
    "\n",
    "    # Merge very close lines (to avoid over-splitting)\n",
    "    merged = []\n",
    "    for ln in lines:\n",
    "        if not merged:\n",
    "            merged.append(ln)\n",
    "            continue\n",
    "        prev = merged[-1]\n",
    "        prev_y = np.mean([ (b[1]+b[3])/2.0 for b in prev ])\n",
    "        cur_y = np.mean([ (b[1]+b[3])/2.0 for b in ln ])\n",
    "        if abs(cur_y - prev_y) < median_h * 0.45:  # merge threshold\n",
    "            merged[-1].extend(ln)\n",
    "        else:\n",
    "            merged.append(ln)\n",
    "\n",
    "    # inside each line sort boxes by x1 ascending (left -> right)\n",
    "    final_lines = []\n",
    "    for ln in merged:\n",
    "        ln_sorted = sorted(ln, key=lambda b: b[0])\n",
    "        final_lines.append([ [int(b[0]), int(b[1]), int(b[2]), int(b[3])] for b in ln_sorted ])\n",
    "\n",
    "    return final_lines\n",
    "\n",
    "# ---------------------------\n",
    "# PHÁT HIỆN CỘT BẰNG GAP TRÊN X_CENTER\n",
    "# ---------------------------\n",
    "def detect_columns_by_x_gaps(lines, min_gap_factor=1.5):\n",
    "    \"\"\"\n",
    "    lines: list of lines (each is list of boxes [x1,y1,x2,y2])\n",
    "    Ý tưởng: compute x_center for each line (mean of boxes), sort them; \n",
    "    find big gaps -> define column boundaries\n",
    "    Trả về: list of columns, mỗi column là list of lines\n",
    "    \"\"\"\n",
    "    if not lines:\n",
    "        return []\n",
    "\n",
    "    line_centers = [ np.mean([ (b[0]+b[2])/2.0 for b in line ]) for line in lines ]\n",
    "    sorted_idx = np.argsort(line_centers)\n",
    "    centers_sorted = [line_centers[i] for i in sorted_idx]\n",
    "\n",
    "    # nếu ít lines thì 1 cột\n",
    "    if len(centers_sorted) < 4:\n",
    "        return [ [lines[i] for i in sorted_idx] ]\n",
    "\n",
    "    # compute gaps between adjacent centers\n",
    "    gaps = [ centers_sorted[i+1] - centers_sorted[i] for i in range(len(centers_sorted)-1) ]\n",
    "    median_gap = np.median(gaps) if gaps else 0.0\n",
    "    if median_gap <= 0:\n",
    "        median_gap = np.mean(gaps) if gaps else 50.0\n",
    "\n",
    "    # find split points where gap is significantly larger than typical\n",
    "    split_indices = []\n",
    "    threshold = median_gap * min_gap_factor\n",
    "    for i,g in enumerate(gaps):\n",
    "        if g > threshold:\n",
    "            split_indices.append(i)\n",
    "\n",
    "    # build boundaries over sorted_idx\n",
    "    columns = []\n",
    "    start = 0\n",
    "    for si in split_indices:\n",
    "        group_idx = sorted_idx[start:si+1]\n",
    "        columns.append([ lines[i] for i in group_idx ])\n",
    "        start = si+1\n",
    "    # last group\n",
    "    group_idx = sorted_idx[start: len(sorted_idx)]\n",
    "    columns.append([ lines[i] for i in group_idx ])\n",
    "\n",
    "    # sort lines inside each column by y (top -> bottom)\n",
    "    for col in columns:\n",
    "        col.sort(key=lambda ln: np.mean([ (b[1]+b[3])/2.0 for b in ln ]))\n",
    "\n",
    "    # sort columns left -> right by their mean x center\n",
    "    columns.sort(key=lambda col: np.mean([ np.mean([ (b[0]+b[2])/2.0 for b in ln ]) for ln in col for b in ln ]))\n",
    "    return columns\n",
    "\n",
    "# ---------------------------\n",
    "# TOÀN BỘ PIPELINE SẮP XẾP (LEFT->RIGHT reading order)\n",
    "# ---------------------------\n",
    "def sort_boxes_reading_order(boxes):\n",
    "    \"\"\"\n",
    "    boxes: list of [x1,y1,x2,y2]\n",
    "    Trả về: final_lines_ordered: list of lines (each line list of boxes)\n",
    "    Reading order implemented: iterate columns left->right, within column top->bottom\n",
    "    \"\"\"\n",
    "    # 1) group into lines\n",
    "    lines = group_lines_by_median(boxes, med_h_factor=0.6)\n",
    "\n",
    "    # 2) detect columns using x gaps\n",
    "    columns = detect_columns_by_x_gaps(lines, min_gap_factor=1.6)\n",
    "\n",
    "    # 3) final assembly: for each column left->right, append its lines in top->bottom\n",
    "    final_lines = []\n",
    "    for col in columns:\n",
    "        # col already sorted by y\n",
    "        for ln in col:\n",
    "            # ensure boxes inside line sorted left->right\n",
    "            ln_sorted = sorted(ln, key=lambda b: b[0])\n",
    "            final_lines.append(ln_sorted)\n",
    "\n",
    "    return final_lines\n",
    "\n",
    "# ---------------------------\n",
    "# CONFIG VIETOCR\n",
    "# ---------------------------\n",
    "config = Cfg.load_config_from_file('D:/pbl6_be_v2/app/config/myconfig.yml')\n",
    "config['weights'] = 'D:/pbl6_be_v2/app/weights/mymodelOCR.pth'\n",
    "config['device'] = 'cpu'\n",
    "detector = Predictor(config)\n",
    "\n",
    "# ---------------------------\n",
    "# INPUT (gán img_path trước khi chạy)\n",
    "# ---------------------------\n",
    "image_path = img_path\n",
    "boxes_path = 'D:/pbl6_be_v2/result_detect.txt'\n",
    "\n",
    "img = cv2.imread(image_path)\n",
    "if img is None:\n",
    "    raise FileNotFoundError(f\"Không tìm thấy ảnh tại: {image_path}\")\n",
    "\n",
    "H, W = img.shape[:2]\n",
    "\n",
    "# ---------------------------\n",
    "# ĐỌC BOX TỪ FILE\n",
    "# ---------------------------\n",
    "boxes = []\n",
    "with open(boxes_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        parts = line.replace(\",\", \" \").strip().split()\n",
    "        if not parts:\n",
    "            continue\n",
    "        try:\n",
    "            parts_f = list(map(float, parts))\n",
    "        except:\n",
    "            continue\n",
    "        if len(parts_f) < 8:\n",
    "            continue\n",
    "        coords = parts_f[:8]\n",
    "        xs = coords[0::2]\n",
    "        ys = coords[1::2]\n",
    "        x1, y1 = int(min(xs)), int(min(ys))\n",
    "        x2, y2 = int(max(xs)), int(max(ys))\n",
    "        # clamp\n",
    "        x1 = clamp(x1, 0, W-1)\n",
    "        x2 = clamp(x2, 0, W-1)\n",
    "        y1 = clamp(y1, 0, H-1)\n",
    "        y2 = clamp(y2, 0, H-1)\n",
    "        # ignore degenerate\n",
    "        if x2 <= x1 or y2 <= y1:\n",
    "            continue\n",
    "        boxes.append([x1, y1, x2, y2])\n",
    "\n",
    "print(f\"Đã đọc {len(boxes)} box từ file detect\")\n",
    "\n",
    "# ---------------------------\n",
    "# SẮP XẾP THEO THỨ TỰ ĐỌC (LEFT -> RIGHT)\n",
    "# ---------------------------\n",
    "lines = sort_boxes_reading_order(boxes)\n",
    "print(f\"Gom thành {len(lines)} dòng (theo reading order left->right).\")\n",
    "\n",
    "# ---------------------------\n",
    "# VẼ DEBUG\n",
    "# ---------------------------\n",
    "debug_img = img.copy()\n",
    "idx = 0\n",
    "for ln in lines:\n",
    "    for (x1,y1,x2,y2) in ln:\n",
    "        cv2.rectangle(debug_img, (x1,y1), (x2,y2), (0,255,0), 2)\n",
    "        cv2.putText(debug_img, str(idx), (x1, max(0,y1-6)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 1, cv2.LINE_AA)\n",
    "        idx += 1\n",
    "\n",
    "dbg_out = \"D:/pbl6_be_v2/sorted_boxes_debug.jpg\"\n",
    "cv2.imwrite(dbg_out, debug_img)\n",
    "print(f\"Đã lưu ảnh debug: {dbg_out}\")\n",
    "\n",
    "# ---------------------------\n",
    "# OCR THEO THỨ TỰ MỚI\n",
    "# ---------------------------\n",
    "final_lines_texts = []\n",
    "for ln in lines:\n",
    "    line_texts = []\n",
    "    for (x1,y1,x2,y2) in ln:\n",
    "        try:\n",
    "            crop = img[y1:y2, x1:x2]\n",
    "            if crop.size == 0:\n",
    "                continue\n",
    "            crop_pil = Image.fromarray(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))\n",
    "            txt = detector.predict(crop_pil)\n",
    "            if isinstance(txt, str):\n",
    "                txt = txt.strip()\n",
    "            else:\n",
    "                txt = str(txt).strip()\n",
    "        except Exception as e:\n",
    "            # nếu OCR lỗi, bỏ box hoặc giữ rỗng\n",
    "            txt = \"\"\n",
    "        if txt:\n",
    "            line_texts.append(txt)\n",
    "    # nối các box trong dòng bằng 1 khoảng trắng\n",
    "    final_lines_texts.append(\" \".join(line_texts))\n",
    "\n",
    "# Ghép các dòng: vì reading order đã left->right (cột trái->phải) và trong cột top->bottom,\n",
    "# mỗi phần tử final_lines_texts tương ứng 1 line trong thứ tự đọc.\n",
    "final_text = \"\\n\".join([ln for ln in final_lines_texts if ln.strip() != \"\"])\n",
    "\n",
    "# ---------------------------\n",
    "# LƯU KẾT QUẢ\n",
    "# ---------------------------\n",
    "out_path = \"D:/pbl6_be_v2/ocr_results.txt\"\n",
    "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(final_text)\n",
    "\n",
    "print(f\"✔ Đã hoàn thành OCR và lưu kết quả vào: {out_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
