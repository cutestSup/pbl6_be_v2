{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2271708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is inserted to verify the fix\n",
    "print(\"Verification cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "667f07ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load from imagenet\n",
      "Số box detect được: 313\n",
      "Đã lưu kết quả detect vào result_detect.txt\n",
      "Đã lưu ảnh kết quả: result_detect.jpg\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import yaml\n",
    "import numpy as np\n",
    "from addict import Dict\n",
    "from pathlib import Path\n",
    "from segmentation.models import build_model\n",
    "from segmentation.post_processing import get_post_processing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class SimpleTextPreprocessor:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def preprocess(self, img_bgr, short_size=736, img_name=None):\n",
    "        h, w = img_bgr.shape[:2]\n",
    "        scale = short_size / min(h, w)\n",
    "        new_h = int(h * scale)\n",
    "        new_w = int(w * scale)\n",
    "\n",
    "        new_h = (new_h + 31) // 32 * 32\n",
    "        new_w = (new_w + 31) // 32 * 32\n",
    "\n",
    "        img_resized = cv2.resize(img_bgr, (new_w, new_h))\n",
    "\n",
    "        gray = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "        binary = cv2.adaptiveThreshold(\n",
    "            blurred,\n",
    "            255,\n",
    "            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "            cv2.THRESH_BINARY,\n",
    "            blockSize=15,\n",
    "            C=10\n",
    "        )\n",
    "\n",
    "        binary_bgr = cv2.cvtColor(binary, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        img_tensor = (\n",
    "            torch.from_numpy(binary_bgr)\n",
    "            .permute(2, 0, 1)\n",
    "            .unsqueeze(0)\n",
    "            .float() / 255.0\n",
    "        )\n",
    "\n",
    "        return img_tensor, binary_bgr, (new_h, new_w)\n",
    "\n",
    "preprocessor = SimpleTextPreprocessor()\n",
    "\n",
    "def preprocess_intelligent(img_bgr, short_size=736, img_name=None):\n",
    "    return preprocessor.preprocess(img_bgr, short_size, img_name)\n",
    "\n",
    "def visualize_detection(img, boxes, scores, conf_threshold=0.5):\n",
    "    result = img.copy()\n",
    "\n",
    "    for box, score in zip(boxes, scores):\n",
    "        if score < conf_threshold:\n",
    "            continue\n",
    "\n",
    "        pts = np.array(box, dtype=np.int32).reshape(-1, 1, 2)\n",
    "        cv2.polylines(result, [pts], True, (0, 255, 0), 2)\n",
    "\n",
    "        x1, y1 = int(box[0][0]), int(box[0][1])\n",
    "        cv2.putText(result, f'{score:.2f}', (x1, y1 - 5),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 1)\n",
    "\n",
    "    return result\n",
    "\n",
    "with open(\"D:/pbl6_be_v2/app/config/icdar2015_resnet18_FPN_DBhead_polyLR.yaml\", \"r\") as f:\n",
    "    cfg = Dict(yaml.safe_load(f))\n",
    "\n",
    "if \"in_channels\" not in cfg[\"arch\"][\"backbone\"]:\n",
    "    cfg[\"arch\"][\"backbone\"][\"in_channels\"] = 3\n",
    "\n",
    "model = build_model(cfg[\"arch\"])\n",
    "\n",
    "checkpoint = torch.load(\n",
    "    \"D:/pbl6_be_v2/app/weights/model_best.pth\",\n",
    "    map_location=\"cpu\"\n",
    ")\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "model.eval()\n",
    "\n",
    "post_process = get_post_processing(cfg[\"post_processing\"])\n",
    "\n",
    "img_path = \"D:/pbl6_be_v2/test_jpg.jpg\"\n",
    "img_bgr = cv2.imread(img_path)\n",
    "\n",
    "if img_bgr is None:\n",
    "    raise FileNotFoundError(f\"Không đọc được ảnh: {img_path}\")\n",
    "\n",
    "orig_h, orig_w = img_bgr.shape[:2]\n",
    "\n",
    "img_tensor, preprocessed_bgr, (target_h, target_w) = preprocess_intelligent(\n",
    "    img_bgr, 736, Path(img_path).stem\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    preds = model(img_tensor)\n",
    "\n",
    "batch = {\"shape\": [(orig_h, orig_w)]}\n",
    "boxes, scores = post_process(batch, preds, is_output_polygon=False)\n",
    "\n",
    "print(f\"Số box detect được: {len(boxes[0])}\")\n",
    "\n",
    "output_txt = \"result_detect.txt\"\n",
    "with open(output_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "    for i, box in enumerate(boxes[0]):\n",
    "        score = scores[0][i] if scores is not None else 1.0\n",
    "        coords = [f\"{int(x)},{int(y)}\" for (x, y) in box]\n",
    "        f.write(f\"{','.join(coords)},{score:.2f}\\n\")\n",
    "\n",
    "print(f\"Đã lưu kết quả detect vào {output_txt}\")\n",
    "\n",
    "img_show = img_bgr.copy()\n",
    "for i, box in enumerate(boxes[0]):\n",
    "    pts = np.array(box, np.int32).reshape((-1, 1, 2))\n",
    "    cv2.polylines(img_show, [pts], True, (0, 255, 0), 2)\n",
    "\n",
    "cv2.imwrite(\"result_detect.jpg\", img_show)\n",
    "print(\"Đã lưu ảnh kết quả: result_detect.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52315b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã đọc 293 boxes.\n",
      "Median Box Height: 16.00\n",
      "Đã gom thành 30 dòng\n",
      "Đã lưu kết quả OCR vào: D:/pbl6_be_v2/ocr_results_optimized.txt\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "from vietocr.tool.predictor import Predictor\n",
    "from vietocr.tool.config import Cfg\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "\n",
    "def sort_boxes_reading_order(boxes):\n",
    "\n",
    "    if not boxes: return []\n",
    "    clean_boxes = []\n",
    "    for b in boxes:\n",
    "        if len(b) < 4: continue\n",
    "        x1, y1, x2, y2 = b[:4]\n",
    "        if x2 > x1 and y2 > y1 and (x2 - x1) >= 2 and (y2 - y1) >= 2:\n",
    "            if x1 == 0 and y1 == 0 and x2 == 0 and y2 == 0:\n",
    "                continue\n",
    "            clean_boxes.append([x1, y1, x2, y2])\n",
    "    if not clean_boxes: return []\n",
    "    \n",
    "    heights = [b[3] - b[1] for b in clean_boxes]\n",
    "    avg_h = np.median(heights) if heights else 10\n",
    "    print(f\"Median Box Height: {avg_h:.2f}\")\n",
    "    \n",
    "    boxes_with_cy = [(b, (b[1] + b[3]) / 2) for b in clean_boxes]\n",
    "    boxes_with_cy.sort(key=lambda x: (x[1], x[0][0]))\n",
    "    \n",
    "    lines = []\n",
    "    threshold = 11.3\n",
    "    \n",
    "    for box, cy in boxes_with_cy:\n",
    "        best_line_idx = -1\n",
    "        best_distance = threshold + 1\n",
    "        \n",
    "        for idx, line in enumerate(lines):\n",
    "            line_cy_avg = np.mean([(b[1] + b[3]) / 2 for b in line])\n",
    "            distance = abs(cy - line_cy_avg)\n",
    "            \n",
    "            if distance <= threshold and distance < best_distance:\n",
    "                best_distance = distance\n",
    "                best_line_idx = idx\n",
    "        \n",
    "        if best_line_idx >= 0:\n",
    "            lines[best_line_idx].append(box)\n",
    "        else:\n",
    "            lines.append([box])\n",
    "    \n",
    "    lines.sort(key=lambda line: np.mean([b[1] for b in line]))\n",
    "    \n",
    "    final_lines = []\n",
    "    for line in lines:\n",
    "        line.sort(key=lambda b: b[0])\n",
    "        final_lines.append(line)\n",
    "    \n",
    "    print(f\"Đã gom thành {len(final_lines)} dòng\")\n",
    "    \n",
    "    return final_lines\n",
    "\n",
    "def enhance_image_for_ocr(image):\n",
    "    if len(image.shape) == 3:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = image\n",
    "    denoised = cv2.fastNlMeansDenoising(gray, None, 10, 7, 21)\n",
    "    return denoised\n",
    "\n",
    "def postprocess_text(text):\n",
    "    if not text: return \"\"\n",
    "    text = text.strip()\n",
    "    replacements = {'|': 'I', '[': '(', ']': ')'}\n",
    "    for k, v in replacements.items():\n",
    "        text = text.replace(k, v)\n",
    "    return text\n",
    "\n",
    "def main():\n",
    "    config = Cfg.load_config_from_file('D:/pbl6_be_v2/app/config/myconfig.yml')\n",
    "    config['weights'] = 'D:/pbl6_be_v2/app/weights/myModelOCR.pth'\n",
    "    config['device'] = 'cpu'\n",
    "    detector = Predictor(config)\n",
    "    \n",
    "    image_path = img_path\n",
    "    boxes_path = 'D:/pbl6_be_v2/result_detect.txt'\n",
    "    \n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Warning: Không tìm thấy ảnh {image_path}, thử dùng biến toàn cục nếu có.\")\n",
    "        try:\n",
    "            img = img_bgr \n",
    "        except:\n",
    "            raise FileNotFoundError(f\"Không tìm thấy ảnh: {image_path}\")\n",
    "\n",
    "    H, W = img.shape[:2]\n",
    "    boxes = []\n",
    "    if os.path.exists(boxes_path):\n",
    "        with open(boxes_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                parts = line.replace(\",\", \" \").strip().split()\n",
    "                if len(parts) < 8: continue\n",
    "                try:\n",
    "                    coords = list(map(float, parts[:8]))\n",
    "                    xs = coords[0::2]; ys = coords[1::2]\n",
    "                    x1, y1, x2, y2 = int(min(xs)), int(min(ys)), int(max(xs)), int(max(ys))\n",
    "                    x1 = max(0, x1); y1 = max(0, y1); x2 = min(W, x2); y2 = min(H, y2)\n",
    "                    if x2 > x1 and y2 > y1:\n",
    "                        boxes.append([x1, y1, x2, y2])\n",
    "                except:\n",
    "                    continue\n",
    "    else:\n",
    "        print(\"Không tìm thấy file result_detect.txt\")\n",
    "        return\n",
    "\n",
    "    print(f\"Đã đọc {len(boxes)} boxes.\")\n",
    "\n",
    "    lines = sort_boxes_reading_order(boxes)\n",
    "\n",
    "    debug_img = img.copy()\n",
    "    line_idx = 0\n",
    "    for line in lines:\n",
    "        color = (np.random.randint(0,255), np.random.randint(0,255), np.random.randint(0,255))\n",
    "        for box in line:\n",
    "            x1, y1, x2, y2 = box[:4]\n",
    "            cv2.rectangle(debug_img, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(debug_img, str(line_idx), (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "        line_idx += 1\n",
    "    cv2.imwrite(\"D:/pbl6_be_v2/sorted_boxes_debug_robust.jpg\", debug_img)\n",
    "\n",
    "    final_results = []\n",
    "    for line in lines:\n",
    "        line_text_parts = []\n",
    "        for box in line:\n",
    "            x1, y1, x2, y2 = box[:4]\n",
    "            crop = img[y1:y2, x1:x2]\n",
    "            if crop.size == 0:\n",
    "                continue\n",
    "            crop_pil = Image.fromarray(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))\n",
    "            text = detector.predict(crop_pil)\n",
    "            text = postprocess_text(text)\n",
    "            line_text_parts.append(text)\n",
    "        full_line_text = \" \".join(line_text_parts)\n",
    "        final_results.append(full_line_text)\n",
    "\n",
    "    out_path = \"D:/pbl6_be_v2/ocr_results_optimized.txt\"\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(final_results))\n",
    "    print(f\"Đã lưu kết quả OCR vào: {out_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
